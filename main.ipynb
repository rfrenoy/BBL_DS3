{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.special import gamma\n",
    "from math import pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The curse of dimensionality\n",
    "\n",
    "What does it mean for you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Thinking in high-dimensional spaces is hard, and intuitions we build from low-dimensional spaces sometimes go wrong. Here is a list of counter-intuitive results *(Verleysen et al., 2003)*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**1. Volume behaves oddly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "dimensions = np.arange(1, 30, 0.1)\n",
    "\n",
    "unit_hyper_sphere_volume = []\n",
    "for d in dimensions:\n",
    "    unit_hyper_sphere_volume.append(pi**(d/2)/gamma(d/2 + 1))\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "plt.title('Volume of a unit-radius hypersphere as a function of space size')\n",
    "plt.xlabel('Number of dimensions in space')\n",
    "plt.plot(dimensions, unit_hyper_sphere_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In high dimensional spaces, a unit hypersphere is almost empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "dimensions = np.arange(1, 30, 0.1)\n",
    "\n",
    "radius = 1\n",
    "epsilon=0.1\n",
    "hyper_sphere_volume = []\n",
    "smaller_hyper_sphere_volume = []\n",
    "\n",
    "for d in dimensions:\n",
    "    hyper_sphere_volume.append(pi**(d/2) * radius**d / gamma(d/2 + 1))\n",
    "    smaller_hyper_sphere_volume.append(pi**(d/2) * (radius-epsilon)**d / gamma(d/2 + 1))\n",
    "    \n",
    "ratios = np.divide(np.array(smaller_hyper_sphere_volume), np.array(hyper_sphere_volume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "plt.title('Ratio between the volume of a 0.9 and a 1 radius sphere as a function of space size')\n",
    "plt.xlabel('Number of dimensions in space')\n",
    "plt.plot(dimensions, ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In high dimensional spaces, the volume of an hyper space concentrates on its outer shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "dimensions = np.arange(0, 8, 0.1)\n",
    "\n",
    "nb_points_in_unit_hypercube = []\n",
    "for d in dimensions:\n",
    "    nb_points_in_unit_hypercube.append(10**d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "plt.title('Number of points needed to fill a 0.1 grid as a function of space size')\n",
    "plt.xlabel('Number of dimensions in space')\n",
    "plt.plot(dimensions, nb_points_in_unit_hypercube)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The higher the number of dimensions, the sparser the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = np.arange(1, 200, 1)\n",
    "nb_points = 1000\n",
    "\n",
    "means = []\n",
    "stds = []\n",
    "for d in dimensions:\n",
    "    points = np.random.random_sample((d, nb_points))\n",
    "    norms = np.sqrt(np.diag(np.matmul(points.T, points)))\n",
    "    means.append(np.mean(norms))\n",
    "    stds.append(np.std(norms))\n",
    "    \n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 5), dpi=100, sharex=True)\n",
    "axes[0].plot(means, label='Mean norm of vector samples')\n",
    "axes[1].plot(stds, label='Standard deviations of the norm of vector samples')\n",
    "[ax.legend() for ax in axes]\n",
    "plt.xlabel('Nb of dimensions')\n",
    "fig.suptitle('Mean and std of the norm of vector samples as we increase the nb of dimensions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def distance_to_nearest_and_furthest_neighboors(point, neighboors):\n",
    "    nearest = np.inf\n",
    "    furthest = -np.inf\n",
    "    for n in neighboors:\n",
    "        dist = np.linalg.norm(n-point, 2)\n",
    "        if dist < nearest:\n",
    "            nearest = dist\n",
    "        elif dist >= furthest:\n",
    "            furthest = dist\n",
    "    return nearest, furthest\n",
    "\n",
    "dimensions = np.arange(1, 100, 1)\n",
    "nb_points = 100\n",
    "\n",
    "distances = []\n",
    "for d in dimensions:\n",
    "    points = np.random.random_sample((d, nb_points))\n",
    "    nearest_dists = []\n",
    "    furthest_dists = []\n",
    "    for i, p in enumerate(points.T):\n",
    "        others = np.vstack([points.T[:i], points.T[i+1:]])\n",
    "        nearest_dist, furthest_dist = distance_to_nearest_and_furthest_neighboors(p, others)\n",
    "        nearest_dists.append(nearest_dist)\n",
    "        furthest_dists.append(furthest_dist)\n",
    "    mean_nearest_dists = np.mean(nearest_dists)\n",
    "    mean_furthest_dists = np.mean(furthest_dists)\n",
    "    distances.append((mean_furthest_dists-mean_nearest_dists) / mean_nearest_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5), dpi=100)\n",
    "plt.title('Contrast between the mean distances of randomly-chosen points to their furthest and nearest neighbor')\n",
    "plt.xlabel('Number of dimensions in space')\n",
    "plt.plot(dimensions, distances)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There is no sense in using \"classic\" similarities in high dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Why does it matter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's look at the objective of generating \"fake\" data. Why would we do that?\n",
    "\n",
    "1. Richard Feynman: *\"What I cannot create, I cannot understand\"*\n",
    "2. Various use of generated data:\n",
    "    * Data augmentation\n",
    "    * Image/Audio \"super resolution\"\n",
    "    * Machine translation\n",
    "    * Image translation\n",
    "    * Imitation learning\n",
    "    \n",
    "How would you generate data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One solution would be to learn the underlying probability distribution of our data, let's call it $p(X)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = np.random.normal(size=1000)\n",
    "plt.scatter(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "x = np.random.normal(size=(2,500))\n",
    "ax.scatter(x[0], x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We see that points are further away from each other. We cannot plot in more than 3 dimensions, but as we have seen earlier, space will become sparser as we add new dimensions. We will need a therotically-infinite amount of data (and computation power) to be able to learn $p(X)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "An idea would be to learn a representation of our data in a lower-dimensional space. A lot of possibilities exist to do that: Principal Component Analysis, Latent Dirichlet Allocation, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's look at Auto-Encoders: their goal is twofold:\n",
    "1. *to create some code* of the original signal (here an image) in a lower-dimensional space\n",
    "2. *to recreate the closest signal possible* to the initial signal from the lower-dimensional code\n",
    "\n",
    "\n",
    "![Let's look at Auto-Encoders](img/ae.png)\n",
    "\n",
    "(Credits: https://danijar.com/building-variational-auto-encoders-in-tensorflow/)\n",
    "\n",
    "One of the most common objective function for auto-encoders is the reconstruction error:\n",
    "\n",
    "\\begin{equation}\n",
    "\\arg\\,\\min_{\\theta, \\phi} E\\,\\big[L(x,\\,g_\\phi(f_\\theta(x))\\big]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What do you think about the Decoder part of the Auto-encoder?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It generates a high-dimensional signal from a low-dimensional representation of the signal. Looks like a generator that got rid of the issue of high-dimensional spaces!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Or did it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A very small image would be 28\\*28 = 784 dimensions (let's say we have binarized the color scale in black or white to make the problem... hum... less difficult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To be able to reconstruct the data, we need a low-dimensional space that is not so low-dimensional (let's say 64 dimensions). 64 is far less than 784, but it is still a lot of dimensions. What do you think the big issue is for the decoder part if we consider it as a generative model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The encoder will create code in a 64-dimensions space. If we take the MNIST data, we have 10 classes. The encoder will map the 784-dimensions input signal into some representation in 64-dimension space. If we sample some random point in this 64 dimensional space, give it to the decoder to generate an image, we will almost surely create an image displaying random noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Is it a lost cause then?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "When you do not have enough data, or if your model is untractable, one solution might be to add some prior knowledge. Let's come back to our auto-encoder:\n",
    "\n",
    "![Let's look at Auto-Encoders](img/ae.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's say that our encoder should map the 784-dimensions input signal into not just a 64-dimensions space but a 64-dimensions multivariate gaussian $p(Z) \\sim \\mathcal{N}(\\mathcal{0},\\,\\sigma^2\\,I)\\,$\n",
    "\n",
    "We can show that this prior can be enforced by learning on the variational lower bound or ELBO (Evidence Lower BOund):\n",
    "\n",
    "\\begin{equation}\n",
    "E_{q_\\phi}\\,\\big[p_{\\theta}\\,(X\\,|\\,Z))\\big] \\times KL(q_{\\phi}(Z\\,|\\,X)\\,||\\,p(Z))\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's say that our encoder should map the 784-dimensions input signal into not just a 64-dimensions space but a 64-dimensions multivariate gaussian $p(Z) \\sim \\mathcal{N}(\\mathcal{0},\\,\\sigma^2\\,I)\\,$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\begin{equation}\n",
    "p(X) = \\int_Z p(X, Z)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\begin{equation}\n",
    "\\log p(X) = \\log \\int_Z p(X, Z)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\begin{equation}\n",
    "\\log p(X) = \\log \\int_Z p(X, Z)\\,\\frac{q(Z\\,|\\,X)}{q(Z\\,|\\,X)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\begin{equation}\n",
    "\\log p(X) = \\log \\int_Z \\frac{p(X, Z)}{q(Z\\,|\\,X)}\\,q(Z\\,|\\,X)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\\begin{equation}\n",
    "\\log p(X) = \\log \\int_Z \\frac{p(X, Z)}{q(Z\\,|\\,X)}\\,q(Z\\,|\\,X)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\begin{equation}\n",
    "\\log p(X) = \\log E_{q(Z\\,|\\,X)} \\big[\\frac{p(X, Z)}{q(Z\\,|\\,X)}\\big]\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Here we must remember that one of the definition of the expected value of a random variable:\n",
    "\n",
    "$$E_g(X) = \\int_\\mathbb{R} g(x)~f(x)~dx$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\begin{equation}\n",
    "\\log p(X) \\geq E_{q(Z\\,|\\,X)} \\log \\big[\\frac{p(X, Z)}{q(Z\\,|\\,X)}\\big]\n",
    "\\end{equation}\n",
    "\n",
    "[Jensen's inequality](https://en.wikipedia.org/wiki/Jensen%27s_inequality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\\begin{equation}\n",
    "\\log p(X) \\geq E_{q(Z\\,|\\,X)} \\log \\big[\\frac{p(X, Z)}{q(Z\\,|\\,X)}\\big]\n",
    "\\end{equation}\n",
    "\n",
    "[Jensen's inequality](https://en.wikipedia.org/wiki/Jensen%27s_inequality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\begin{equation}\n",
    "\\log p(X) \\geq E_{q(Z\\,|\\,X)} \\log \\frac{p(X\\,|\\,Z)\\,p(Z)}{q(Z\\,|\\,X)}\n",
    "\\end{equation}\n",
    "\n",
    "*(remember that $P(A, B) = P(A~|~B) \\times P(B)$)*\n",
    "\n",
    "\n",
    "Note that we made our prior $p(Z)$ appear!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\begin{equation}\n",
    "\\log p(X) \\geq E_{q(Z\\,|\\,X)} \\log p(X\\,|\\,Z) + E_{q(Z\\,|\\,X)} \\log p(Z) - E_{q(Z\\,|\\,X)} \\log q(Z\\,|\\,X)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\begin{equation}\n",
    "\\log p(X) \\geq E_{q(Z\\,|\\,X)} \\log p(X\\,|\\,Z) - \\big[E_{q(Z\\,|\\,X)} \\log q(Z\\,|\\,X) - E_{q(Z\\,|\\,X)} \\log p(Z) \\big]\n",
    "\\end{equation}\n",
    "\n",
    "Recall that $$KL(P\\,||\\,Q) = E_p \\big[\\log \\frac{P}{Q}\\big]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\\begin{equation}\n",
    "\\log p(X) \\geq E_{q(Z\\,|\\,X)} \\log p(X\\,|\\,Z) - \\big[E_{q(Z\\,|\\,X)} \\log q(Z\\,|\\,X) - E_{q(Z\\,|\\,X)} \\log p(Z) \\big]\n",
    "\\end{equation}\n",
    "\n",
    "Recall that $$KL(P\\,||\\,Q) = E_p \\big[\\log \\frac{P}{Q}\\big]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\begin{equation}\n",
    "\\log p(X) \\geq E_{q(Z\\,|\\,X)} \\log p(X\\,|\\,Z) - KL(q(Z\\,|\\,X)\\,||\\,p(Z))\n",
    "\\end{equation}\n",
    "\n",
    "Note the trade-off between encoding and decoding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Time to try!\n",
    "\n",
    "1. Create an account on [Google Colab](https://colab.research.google.com)\n",
    "\n",
    "2. Clone the BBL repository:\n",
    "\n",
    "    ```sh\n",
    "    git clone git@gitlab.octo.com:rfrenoy/bbl_ds3.git\n",
    "    ```\n",
    "\n",
    "3. And upload `cvae.ipynb` into Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What about [Generative Adversarial Networks (GANs)](https://arxiv.org/pdf/1406.2661.pdf)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Another way to solve the intractable likelihood problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "VAE did *approximate inference* by using a prior on the latent variable distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "GAN use *likelihood-free* inference.\n",
    "\n",
    "What's the difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In VAE, we approximated the posterior distribution $$q(Z\\,|\\,X) \\approx p(Z)$$, where $$p(Z)$$ is a simple distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In GANs, we want to sample directly from the \"real\" distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We want to do this by \"playing\" a two-player game, where:\n",
    "\n",
    "* a discriminant tries to classify as good as possible data sampled from a real dataset and data generated by the generator\n",
    "    $$E_{x \\sim p_{data}(x)} \\log D_\\phi(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Maximizing this term corresponds to $D$ being able to precisely predict $D(x)=1$ when $x\\sim p_{data}(x)$. So **the discriminant tries to maximize** this term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* a generator G on the other hand tries to generate fake data that is undistinguishable from real data. The generator wants to maximize\n",
    "    $$E_{x \\sim p_\\theta(x)} \\log (1 - D_\\phi(G(x)))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Remember that $\\log x < 0$ when $x < 1$, so maximizing the previous value means that $D(G(z)) \\approx 0$, which means the discriminator is winning. So **the generator tries to minimize** this term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "All in all, the game is to find\n",
    "\n",
    "\\begin{equation}\n",
    "\\min_\\theta \\max_\\phi E_{x \\sim p_\\theta(x)} \\log (1 - D_\\phi(G(x))) + E_{x \\sim p_{data}(x)} \\log D_\\phi(x)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Time to try!\n",
    "\n",
    "1. Go to your [Google Colab account](https://colab.research.google.com)\n",
    "\n",
    "2. And upload `dcgan.ipynb` into Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "bayesian_tutorial",
   "language": "python",
   "name": "bayesian_tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
